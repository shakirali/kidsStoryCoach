"""Integration tests for Page Writer Agent evaluation.

This test module evaluates pages generated by the Page Writer Agent
using the judge agent to ensure quality standards are met.
"""

import pytest
import random
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from agents.sub_agents.page_writer.agent import page_writer_agent
from agents.evaluation.helpers import evaluate_with_judge, call_agent_async
from agents.evaluation.prompts import instruction_page_writer_judge
from agents.evaluation.judge_agent import judge_agent


@pytest.fixture
def session_id():
    """Create a random session id."""
    return str(random.randint(1000000000, 9999999999))


@pytest.fixture
def user_id():
    """Create a random user id."""
    return str(random.randint(1000000000, 9999999999))


@pytest.fixture
def page_writer_app_name():
    return "page_writer_test"


@pytest.fixture
def judge_app_name():
    return "judge_test"


@pytest.fixture
def session_service():
    """Create a session service for tests."""
    return InMemorySessionService()


@pytest.fixture
def page_writer_runner(session_service):
    """Create a runner for the page writer agent."""
    return Runner(
        app_name="page_writer_test",
        agent=page_writer_agent,
        session_service=session_service
    )


@pytest.fixture
def judge_runner(session_service):
    """Create a runner for the judge agent."""
    return Runner(
        app_name="judge_test",
        agent=judge_agent,
        session_service=session_service
    )


# Test cases: (child_description, story_title, story_concept, previous_pages, page_number, expected_min_score)
TEST_CASES = [
    (
        "the knight went to the castle and saw a dragon",
        "The Brave Knight",
        "A brave knight saves a dragon",
        [],
        1,
        3.5
    ),
    (
        "then the dragon became his friend and they flew together",
        "The Brave Knight",
        "A brave knight saves a dragon",
        ["The knight went to the castle and saw a dragon. The dragon was friendly."],
        2,
        3.5
    ),
    (
        "the robot danced and everyone clapped",
        "Dancing Robot",
        "A robot learns to dance",
        [],
        1,
        3.5
    ),
    (
        "in the forest the animals talked to each other",
        "The Enchanted Forest",
        "A magical forest adventure with talking animals",
        [],
        1,
        3.5
    ),
]


@pytest.mark.asyncio
@pytest.mark.parametrize("child_description,story_title,story_concept,previous_pages,page_number,min_score", TEST_CASES)
async def test_page_writer_produces_quality_pages(
    page_writer_runner,
    judge_runner,
    session_service,
    session_id,
    user_id,
    page_writer_app_name,
    judge_app_name,
    child_description,
    story_title,
    story_concept,
    previous_pages,
    page_number,
    min_score
):
    """Test that Page Writer Agent produces pages that meet quality standards."""
    # Step 1: Generate page using Page Writer Agent
    page_session = await session_service.create_session(
        session_id=f"{session_id}_page",
        user_id=user_id,
        app_name=page_writer_app_name
    )
    
    # Format input for page writer
    previous_pages_str = "\n".join(previous_pages) if previous_pages else ""
    page_input = f"""child_page_description: {child_description}
story_title: {story_title}
story_concept: {story_concept}
current_page_number: {page_number}
previous_pages: {previous_pages_str}"""
    
    generated_page = await call_agent_async(
        query=page_input,
        runner=page_writer_runner,
        user_id=user_id,
        session_id=page_session.id
    )
    
    # Clean up the page text
    generated_page = generated_page.strip()
    
    # Verify we got a page
    assert generated_page is not None, "Page writer should return page text"
    assert len(generated_page) > 0, "Page should not be empty"
    
    # Step 2: Evaluate with judge agent
    previous_pages_str_for_judge = "\n".join([f"Page {i+1}: {page}" for i, page in enumerate(previous_pages)]) if previous_pages else "None"
    
    evaluation_input = f"""child_page_description: {child_description}
generated_page_text: {generated_page}
previous_pages: {previous_pages_str_for_judge}
story_title: {story_title}
story_concept: {story_concept}"""
    
    judge_session_id = f"{session_id}_judge"
    evaluation_result = await evaluate_with_judge(
        judge_instruction=instruction_page_writer_judge(),
        evaluation_input=evaluation_input,
        session_service=session_service,
        runner=judge_runner,
        user_id=user_id,
        session_id=judge_session_id,
        app_name=judge_app_name,
        expected_min_score=min_score
    )
    
    # Step 3: Verify evaluation results
    scores = evaluation_result["scores"]
    overall_score = evaluation_result["overall_score"]
    
    # Verify all scores are in valid range
    for score_name, score_value in scores.items():
        assert isinstance(score_value, int), f"{score_name} should be an integer"
        assert 1 <= score_value <= 5, f"{score_name} should be between 1 and 5, got {score_value}"
    
    # Verify overall score meets minimum
    assert overall_score >= min_score, \
        f"Page scored {overall_score}, below minimum {min_score}. " \
        f"Scores: {scores}, Reasoning: {evaluation_result.get('reasoning', 'N/A')}"
    
    # Verify pass status
    assert evaluation_result["pass"] is True, \
        f"Page should pass evaluation. Overall score: {overall_score}, " \
        f"Reasoning: {evaluation_result.get('reasoning', 'N/A')}"
    
    print(f"\nPage {page_number}:")
    print(f"  Child's Input: '{child_description}'")
    print(f"  Generated Page: '{generated_page[:100]}...' (truncated)")
    print(f"  Scores: {scores}")
    print(f"  Overall: {overall_score}")
    print(f"  Reasoning: {evaluation_result.get('reasoning', 'N/A')}")


@pytest.mark.asyncio
async def test_page_writer_preserves_child_voice(
    page_writer_runner,
    judge_runner,
    session_service,
    session_id,
    user_id,
    page_writer_app_name,
    judge_app_name
):
    """Test that Page Writer preserves the child's voice and doesn't over-edit."""
    child_description = "the cat jumped on the table and meowed loudly"
    story_title = "The Adventures of Fluffy"
    story_concept = "A cat's daily adventures"
    
    # Generate page
    page_session = await session_service.create_session(
        session_id=f"{session_id}_page_voice",
        user_id=user_id,
        app_name=page_writer_app_name
    )
    
    page_input = f"""child_page_description: {child_description}
story_title: {story_title}
story_concept: {story_concept}
current_page_number: 1
previous_pages: """
    
    generated_page = await call_agent_async(
        query=page_input,
        runner=page_writer_runner,
        user_id=user_id,
        session_id=page_session.id
    )
    
    generated_page = generated_page.strip()
    
    # Evaluate with focus on voice preservation
    evaluation_input = f"""child_page_description: {child_description}
generated_page_text: {generated_page}
previous_pages: None
story_title: {story_title}
story_concept: {story_concept}"""
    
    judge_session_id = f"{session_id}_judge_voice"
    result = await evaluate_with_judge(
        judge_instruction=instruction_page_writer_judge(),
        evaluation_input=evaluation_input,
        session_service=session_service,
        runner=judge_runner,
        user_id=user_id,
        session_id=judge_session_id,
        app_name=judge_app_name
    )
    
    # Verify voice preservation score is good (>= 3)
    voice_score = result["scores"]["voice_preservation"]
    assert voice_score >= 3, \
        f"Voice preservation score {voice_score} too low. " \
        f"Child said: '{child_description}', Generated: '{generated_page}'"
    
    # Verify minimal intervention score is good (>= 3)
    intervention_score = result["scores"]["minimal_intervention"]
    assert intervention_score >= 3, \
        f"Minimal intervention score {intervention_score} too low. " \
        f"Agent may be over-editing."
    
    print(f"\nVoice Preservation Test:")
    print(f"  Child's Input: '{child_description}'")
    print(f"  Generated: '{generated_page}'")
    print(f"  Voice Preservation Score: {voice_score}/5")
    print(f"  Minimal Intervention Score: {intervention_score}/5")

